

.. _sphx_glr_auto_examples_example_logistic.py:


L1-regularized logistic regression
==================================

Implementation of L1-regularized logistic regression
using copt.



.. code-block:: python

    import numpy as np
    from sklearn.linear_model import logistic
    from copt import proximal_gradient

    n_samples, n_features = 100, 10
    X = np.random.randn(n_samples, n_features)
    y = np.random.randn(n_samples)
    alpha = 1.


    def logloss(x):
        return logistic._logistic_loss(x, X, y, 1.)


    def fprime_logloss(x):
        return logistic._logistic_loss_and_grad(x, X, y, 1.)[1]


    def g_prox(x, step_size):
        """
        prox of alpha * l1
        """
        return np.fmax(x - step_size * alpha, 0) - \
            np.fmax(- x - step_size * alpha, 0)


    out = proximal_gradient(logloss, fprime_logloss, g_prox, np.zeros(n_features))
    print('Solution', out)

**Total running time of the script:** ( 0 minutes  0.000 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: example_logistic.py <example_logistic.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: example_logistic.ipynb <example_logistic.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
